{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "import random\n",
        "import torch.optim as optim\n",
        "from google.colab import drive\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "!pip install mido\n",
        "import mido\n",
        "\n",
        "drive.mount(\"/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fb6igfaABSnd",
        "outputId": "b51fa7a3-3877-4db5-91f3-e5808f42b56e"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mido\n",
            "  Downloading mido-1.2.10-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/51.1 KB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 KB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mido\n",
            "Successfully installed mido-1.2.10\n",
            "Drive already mounted at /drive; to attempt to forcibly remount, call drive.mount(\"/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import sys\n",
        "import os\n",
        "\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "\n",
        "#out = np.load(\"/drive/My Drive/outputs/some.mid_1.npy\")\n",
        "#inp =  np.load(\"/drive/My Drive/inputs/some.mid_1.npy\")"
      ],
      "metadata": {
        "id": "_2kanKYlEDDg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = []\n",
        "output = []\n",
        "\n",
        "input_list = os.listdir(\"/drive/My Drive/inputs\")\n",
        "output_list = os.listdir(\"/drive/My Drive/outputs\")\n",
        "\n",
        "for path in input_list:\n",
        "  try:\n",
        "    arr = np.load('/drive/My Drive/inputs/' + path)\n",
        "    #print('/drive/My Drive/inputs/' + path ,arr.shape)\n",
        "    input.append(arr[:, 12:76])\n",
        "  except:\n",
        "    pass\n",
        "input = np.array(input)\n",
        "input = input[:,np.newaxis , :]\n",
        "\n",
        "for path in output_list:\n",
        "  try:\n",
        "    arr = np.load('/drive/My Drive/outputs/' + path)\n",
        "    output.append(arr[:, 12:76])\n",
        "  except:\n",
        "    pass\n",
        "output = np.array(output)\n",
        "output = output[:, np.newaxis,:]\n",
        "\n",
        "input = torch.Tensor(input)\n",
        "output = torch.Tensor(output)\n",
        "\n",
        "input_dataset = TensorDataset(input)\n",
        "output_dataset = TensorDataset(output)\n",
        "\n",
        "#print(input_dataset.tensors)\n",
        "\n",
        "dataloader = DataLoader(dataset = output_dataset , batch_size= 3)\n",
        "dataloaderG = DataLoader(input_dataset, batch_size= 3 )\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-VlseQw_E1cX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "EYxv1e2SniY5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c845f702-f4d2-4e45-a2df-72a3f288e2bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Seed:  999\n",
            "Generator(\n",
            "  (main): Sequential(\n",
            "    (0): ConvTranspose2d(1, 32, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): ConvTranspose2d(32, 16, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): ConvTranspose2d(16, 8, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): ConvTranspose2d(8, 4, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (10): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): ConvTranspose2d(4, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (13): Tanh()\n",
            "  )\n",
            ")\n",
            "Discriminator(\n",
            "  (main): Sequential(\n",
            "    (0): Conv2d(1, 2, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (2): Conv2d(2, 4, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (5): Conv2d(4, 8, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (6): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (8): Conv2d(8, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (11): Conv2d(16, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "    (12): Sigmoid()\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "manualSeed = 999\n",
        "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
        "print(\"Random Seed: \", manualSeed)\n",
        "random.seed(manualSeed)\n",
        "torch.manual_seed(manualSeed)\n",
        "\n",
        "\n",
        "batchsize = 32\n",
        "inputsize = 4\n",
        "smallest_note =16\n",
        "note_range = 129\n",
        "epochs = 5\n",
        "rate = 0.0002\n",
        "adam_beta = 0.5\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and 1 > 0) else \"cpu\")\n",
        "\n",
        "\n",
        "# Sample Data 4 bars smallest note is 16th note:\n",
        "# Mary had a little lamb \n",
        "#   \n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)\n",
        "\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self, ngpu):\n",
        "        super(Generator, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.main = nn.Sequential(\n",
        "            nn.ConvTranspose2d( 1, 4 * 8, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(4 * 8),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*8) x 4 x 4\n",
        "            nn.ConvTranspose2d(4 * 8, 4 * 4, 4, 1, 1, bias=False),\n",
        "            nn.BatchNorm2d(4 * 4),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*4) x 8 x 8\n",
        "            nn.ConvTranspose2d( 4 * 4, 4 * 2, 4, 1, 1, bias=False),\n",
        "            nn.BatchNorm2d(4 * 2),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*2) x 16 x 16\n",
        "            nn.ConvTranspose2d( 4 * 2, 4, 4, 1, 1, bias=False),\n",
        "            nn.BatchNorm2d(4),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf) x 32 x 32\n",
        "            nn.ConvTranspose2d( 4, 1, 4, 1, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "  def forward(self, input):\n",
        "        return self.main(input)\n",
        "\n",
        "\n",
        "generator = Generator(1).to(device)\n",
        "generator.apply(weights_init)\n",
        "\n",
        "# Print the model\n",
        "print(generator)\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, ngpu):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.main = nn.Sequential(\n",
        "            # input is (nc) x 64 x 64\n",
        "            nn.Conv2d(1, 2, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf) x 32 x 32\n",
        "            nn.Conv2d(2, 2 * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(2 * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf*2) x 16 x 16\n",
        "            nn.Conv2d(2 * 2, 2 * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(2 * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf*4) x 8 x 8\n",
        "            nn.Conv2d(2 * 4, 2 * 8, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(2 * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf*8) x 4 x 4\n",
        "            nn.Conv2d(2 * 8, 1, 4, 1, 0, bias=False),\n",
        "            nn.Sigmoid(),\n",
        "\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)\n",
        "\n",
        "discriminator = Discriminator(1).to(device)\n",
        "\n",
        "discriminator.apply(weights_init)\n",
        "\n",
        "# Print the model\n",
        "print(discriminator)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "real_label = 1.\n",
        "fake_label = 0.\n",
        "\n",
        "# Setup Adam optimizers for both G and D\n",
        "optimizerD = optim.Adam(discriminator.parameters(), lr=rate, betas=(adam_beta, 0.999))\n",
        "optimizerG = optim.Adam(generator.parameters(), lr=rate, betas=(adam_beta, 0.999))"
      ],
      "metadata": {
        "id": "hCjys6w2HeUZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_list = []\n",
        "G_losses = []\n",
        "D_losses = []\n",
        "iters = 0\n",
        "\n",
        "print(\"Starting Training Loop...\")\n",
        "# For each epoch\n",
        "for epoch in range(epochs):\n",
        "    # For each batch in the dataloader\n",
        "    for i, dataT in enumerate(zip(dataloader,dataloaderG), 0):\n",
        "        data, dataG = dataT\n",
        "\n",
        "        discriminator.zero_grad()\n",
        "\n",
        "        real_cpu = data[0].to(device)\n",
        "        b_size = real_cpu.size(0)\n",
        "        label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n",
        "\n",
        "        output = discriminator(real_cpu).view(-1)\n",
        "\n",
        "        errD_real = criterion(output, label)\n",
        "\n",
        "        errD_real.backward()\n",
        "        D_x = output.mean().item()\n",
        "\n",
        "        input = dataG[0].to(device)\n",
        "\n",
        "        fake = generator(input)\n",
        "\n",
        "        label.fill_(fake_label)\n",
        "\n",
        "        output = discriminator(fake.detach()).view(-1)\n",
        "\n",
        "\n",
        "        errD_fake = criterion(output, label)\n",
        "\n",
        "        errD_fake.backward()\n",
        "        D_G_z1 = output.mean().item()\n",
        "\n",
        "        errD = errD_real + errD_fake\n",
        "\n",
        "        optimizerD.step()\n",
        "\n",
        "\n",
        "        generator.zero_grad()\n",
        "        label.fill_(real_label)  \n",
        "        output = discriminator(fake).view(-1)\n",
        "\n",
        "       \n",
        "        errG = criterion(output, label)\n",
        "        \n",
        "        errG.backward()\n",
        "        D_G_z2 = output.mean().item()\n",
        "        \n",
        "        optimizerG.step()\n",
        "\n",
        "  \n",
        "        if i % 50 == 0:\n",
        "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
        "                  % (epoch, epochs, i, len(dataloader),\n",
        "                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
        "\n",
        "        G_losses.append(errG.item())\n",
        "        D_losses.append(errD.item())\n",
        "\n",
        "        iters += 1"
      ],
      "metadata": {
        "id": "kAxWpMclIk_G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "453da843-28bd-4f83-9897-845e9313ee4d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Training Loop...\n",
            "[0/5][0/400]\tLoss_D: 1.5083\tLoss_G: 0.7025\tD(x): 0.4595\tD(G(z)): 0.5173 / 0.4956\n",
            "[0/5][50/400]\tLoss_D: 1.0460\tLoss_G: 1.0715\tD(x): 0.5642\tD(G(z)): 0.3641 / 0.3573\n",
            "[0/5][100/400]\tLoss_D: 1.3179\tLoss_G: 0.6074\tD(x): 0.6570\tD(G(z)): 0.5863 / 0.5450\n",
            "[0/5][150/400]\tLoss_D: 0.8832\tLoss_G: 1.2345\tD(x): 0.6061\tD(G(z)): 0.3071 / 0.2992\n",
            "[0/5][200/400]\tLoss_D: 0.4442\tLoss_G: 1.5891\tD(x): 0.8510\tD(G(z)): 0.2332 / 0.2335\n",
            "[0/5][250/400]\tLoss_D: 0.5875\tLoss_G: 2.0593\tD(x): 0.8072\tD(G(z)): 0.3039 / 0.1341\n",
            "[0/5][300/400]\tLoss_D: 0.3900\tLoss_G: 1.8551\tD(x): 0.8232\tD(G(z)): 0.1724 / 0.1679\n",
            "[0/5][350/400]\tLoss_D: 0.4893\tLoss_G: 1.4580\tD(x): 0.9441\tD(G(z)): 0.3325 / 0.2577\n",
            "[1/5][0/400]\tLoss_D: 0.1304\tLoss_G: 3.0566\tD(x): 0.9298\tD(G(z)): 0.0550 / 0.0486\n",
            "[1/5][50/400]\tLoss_D: 0.1490\tLoss_G: 2.7656\tD(x): 0.9167\tD(G(z)): 0.0600 / 0.0630\n",
            "[1/5][100/400]\tLoss_D: 0.0915\tLoss_G: 3.3797\tD(x): 0.9524\tD(G(z)): 0.0415 / 0.0359\n",
            "[1/5][150/400]\tLoss_D: 0.1327\tLoss_G: 4.0526\tD(x): 0.8934\tD(G(z)): 0.0155 / 0.0209\n",
            "[1/5][200/400]\tLoss_D: 0.1653\tLoss_G: 2.8166\tD(x): 0.9685\tD(G(z)): 0.1185 / 0.1067\n",
            "[1/5][250/400]\tLoss_D: 0.0491\tLoss_G: 4.6943\tD(x): 0.9638\tD(G(z)): 0.0119 / 0.0115\n",
            "[1/5][300/400]\tLoss_D: 0.0394\tLoss_G: 4.1950\tD(x): 0.9770\tD(G(z)): 0.0160 / 0.0156\n",
            "[1/5][350/400]\tLoss_D: 0.0155\tLoss_G: 4.8993\tD(x): 0.9935\tD(G(z)): 0.0089 / 0.0085\n",
            "[2/5][0/400]\tLoss_D: 0.0387\tLoss_G: 4.1237\tD(x): 0.9796\tD(G(z)): 0.0179 / 0.0167\n",
            "[2/5][50/400]\tLoss_D: 0.0186\tLoss_G: 5.0433\tD(x): 0.9902\tD(G(z)): 0.0087 / 0.0072\n",
            "[2/5][100/400]\tLoss_D: 0.0182\tLoss_G: 4.9534\tD(x): 0.9894\tD(G(z)): 0.0074 / 0.0071\n",
            "[2/5][150/400]\tLoss_D: 0.0396\tLoss_G: 3.9472\tD(x): 0.9851\tD(G(z)): 0.0242 / 0.0210\n",
            "[2/5][200/400]\tLoss_D: 0.0380\tLoss_G: 4.5424\tD(x): 0.9914\tD(G(z)): 0.0283 / 0.0275\n",
            "[2/5][250/400]\tLoss_D: 0.0454\tLoss_G: 4.5179\tD(x): 0.9849\tD(G(z)): 0.0292 / 0.0191\n",
            "[2/5][300/400]\tLoss_D: 0.0103\tLoss_G: 6.5330\tD(x): 0.9915\tD(G(z)): 0.0018 / 0.0018\n",
            "[2/5][350/400]\tLoss_D: 0.0174\tLoss_G: 4.2880\tD(x): 0.9978\tD(G(z)): 0.0151 / 0.0139\n",
            "[3/5][0/400]\tLoss_D: 0.0100\tLoss_G: 5.5463\tD(x): 0.9942\tD(G(z)): 0.0042 / 0.0040\n",
            "[3/5][50/400]\tLoss_D: 0.0050\tLoss_G: 6.6957\tD(x): 0.9963\tD(G(z)): 0.0013 / 0.0013\n",
            "[3/5][100/400]\tLoss_D: 0.0060\tLoss_G: 5.8897\tD(x): 0.9969\tD(G(z)): 0.0029 / 0.0028\n",
            "[3/5][150/400]\tLoss_D: 0.0223\tLoss_G: 5.1548\tD(x): 0.9861\tD(G(z)): 0.0082 / 0.0073\n",
            "[3/5][200/400]\tLoss_D: 0.0089\tLoss_G: 5.9337\tD(x): 0.9950\tD(G(z)): 0.0039 / 0.0037\n",
            "[3/5][250/400]\tLoss_D: 0.0121\tLoss_G: 5.6018\tD(x): 0.9924\tD(G(z)): 0.0044 / 0.0043\n",
            "[3/5][300/400]\tLoss_D: 0.0055\tLoss_G: 6.0200\tD(x): 0.9974\tD(G(z)): 0.0029 / 0.0028\n",
            "[3/5][350/400]\tLoss_D: 0.0055\tLoss_G: 5.5399\tD(x): 0.9989\tD(G(z)): 0.0044 / 0.0041\n",
            "[4/5][0/400]\tLoss_D: 0.0090\tLoss_G: 6.3199\tD(x): 0.9942\tD(G(z)): 0.0032 / 0.0024\n",
            "[4/5][50/400]\tLoss_D: 0.0064\tLoss_G: 6.7486\tD(x): 0.9982\tD(G(z)): 0.0046 / 0.0045\n",
            "[4/5][100/400]\tLoss_D: 0.0037\tLoss_G: 7.5116\tD(x): 0.9969\tD(G(z)): 0.0006 / 0.0005\n",
            "[4/5][150/400]\tLoss_D: 0.0137\tLoss_G: 5.6402\tD(x): 0.9918\tD(G(z)): 0.0054 / 0.0052\n",
            "[4/5][200/400]\tLoss_D: 0.0041\tLoss_G: 6.5492\tD(x): 0.9976\tD(G(z)): 0.0017 / 0.0016\n",
            "[4/5][250/400]\tLoss_D: 0.0069\tLoss_G: 6.1770\tD(x): 0.9960\tD(G(z)): 0.0028 / 0.0027\n",
            "[4/5][300/400]\tLoss_D: 0.0026\tLoss_G: 6.6355\tD(x): 0.9989\tD(G(z)): 0.0015 / 0.0015\n",
            "[4/5][350/400]\tLoss_D: 0.0016\tLoss_G: 7.1054\tD(x): 0.9994\tD(G(z)): 0.0011 / 0.0010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def enlarge_matrix(matrix):\n",
        "    \n",
        "    new_matrix = np.empty((0,matrix.shape[1]), matrix.dtype)\n",
        "    for i  in range(matrix.shape[1]):\n",
        "        # Check if the current row index is divisible by 120\n",
        "        for j in range(120):\n",
        "            new_matrix = np.vstack((new_matrix, matrix[:,i]))\n",
        "    return new_matrix"
      ],
      "metadata": {
        "id": "ndj8yaAOX20z"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def arry2mid(ary, tempo=500000):\n",
        "    # get the difference\n",
        "\n",
        "    new_ary = ary #np.concatenate([np.array([[0] * 71]), np.array(ary)], axis=0)\n",
        "    changes = new_ary[1:] - new_ary[:-1]\n",
        "    # create a midi file with an empty track\n",
        "    mid_new = mido.MidiFile()\n",
        "    track = mido.MidiTrack()\n",
        "    mid_new.tracks.append(track)\n",
        "    track.append(mido.MetaMessage('set_tempo', tempo=tempo, time=0))\n",
        "    # add difference in the empty track\n",
        "    last_time = 0\n",
        "    for ch in changes:\n",
        "        if set(ch) == {0}:  # no change\n",
        "            last_time += 1\n",
        "        else:\n",
        "            on_notes = np.where(ch > 0)[0]\n",
        "\n",
        "            on_notes_vol = ch[on_notes]\n",
        "            off_notes = np.where(ch < 0)[0]\n",
        "            first_ = True\n",
        "            for n, v in zip(on_notes, on_notes_vol):\n",
        "\n",
        "                new_time = last_time if first_ else 0\n",
        "                track.append(mido.Message('note_on', note=n + 21, velocity=int(v), time=new_time))\n",
        "                first_ = False\n",
        "            for n in off_notes:\n",
        "                new_time = last_time if first_ else 0\n",
        "                track.append(mido.Message('note_off', note=n + 21, velocity=0, time=new_time))\n",
        "                first_ = False\n",
        "            last_time = 0\n",
        "    return mid_new"
      ],
      "metadata": {
        "id": "frUJMaJ2jQ-8"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "result_array = generator(input[0:1]).cpu().detach().numpy()\n",
        "\n",
        "\n",
        "#result_array = enlarge_matrix(result_array).transpose()\n",
        "result_array = np.where(result_array>0.2, 1, 0)\n",
        "#print(result_array)\n",
        "result_array = result_array[0,0,:,:]\n",
        "print(result_array.shape)\n",
        "plt.plot(range(result_array.shape[0]), np.multiply(np.where(result_array>0, 1, 0), range(1, 72)), marker='.', markersize=1, linestyle='')\n",
        "plt.title(\"midi plot\")\n",
        "plt.show()\n",
        "\n",
        "result_array = enlarge_matrix(result_array)\n",
        "print(result_array.shape)\n",
        "mid = arry2mid(result_array*120)\n",
        "\n",
        "mid.save(\"test.mid\")"
      ],
      "metadata": {
        "id": "wIZVJsFPmDmp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation = input[0].cpu().detach().numpy()[0,:,:]\n",
        "validation = enlarge_matrix(validation)\n",
        "\n",
        "mid2 = arry2mid(validation)\n",
        "mid2.save(\"validation_input.mid\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "wPchydpVpp5u",
        "outputId": "117c67a7-16ba-45a3-b73f-a46cea31a8d8"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nout = output[0].cpu().detach().numpy()\\nprint(out.shape)\\nout = enlarge_matrix(out)\\nmid3 = arry2mid(out)\\nmid3.save(\"vslidation_output.mid\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    }
  ]
}